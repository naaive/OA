{"uid":"6dc17a8b353cd1df","name":"test_query_nft_ranking[3-3]","fullName":"tests.agent_trajectory.market_analysis#test_query_nft_ranking","historyId":"379a39e942b72cd08c1d0081dbc4bc35","time":{"start":1730429125525,"stop":1730429137968,"duration":12443},"status":"broken","statusMessage":"TypeError: NFTRankingExecutor._arun() missing 1 required positional argument: 'limit'","statusTrace":"market_analysis_agent = AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n  agent_scratchpad: Runnab...(name='DuckDuckGoSearchExecutor'), FundingRateExecutor(), PriceExecutor(), CoinMarketExecutor(), NFTRankingExecutor()])\n\n    @pytest.mark.asyncio\n    async def test_query_nft_ranking(market_analysis_agent):\n        events = market_analysis_agent.astream_events(\n            {\"messages\": [HumanMessage(content=\"What are the top 5 NFT collections?\", name=\"human\")]}, version=\"v1\"\n        )\n    \n        tool_end_count = 0\n>       async for event in events:\n\nagent_trajectory/market_analysis.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/runnables/base.py:1246: in astream_events\n    async for event in event_stream:\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/event_stream.py:778: in _astream_events_implementation_v1\n    async for log in _astream_log_implementation(  # type: ignore[misc]\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:670: in _astream_log_implementation\n    await task\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:624: in consume_astream\n    async for chunk in runnable.astream(input, config, **kwargs):\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1595: in astream\n    async for step in iterator:\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent_iterator.py:246: in __aiter__\n    async for chunk in self.agent_executor._aiter_next_step(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1360: in _aiter_next_step\n    result = await asyncio.gather(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1393: in _aperform_agent_action\n    observation = await tool.arun(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tools.py:747: in arun\n    raise error_to_raise\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = NFTRankingExecutor(), tool_input = {}, verbose = True\nstart_color = 'green', color = 'yellow'\ncallbacks = <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7fbea7c7dc90>\ntags = None, metadata = None, run_name = None, run_id = None, config = None\ntool_call_id = None, kwargs = {}\ncallback_manager = <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7fbea6b07690>\n\n    async def arun(\n        self,\n        tool_input: Union[str, Dict],\n        verbose: Optional[bool] = None,\n        start_color: Optional[str] = \"green\",\n        color: Optional[str] = \"green\",\n        callbacks: Callbacks = None,\n        *,\n        tags: Optional[List[str]] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        run_name: Optional[str] = None,\n        run_id: Optional[uuid.UUID] = None,\n        config: Optional[RunnableConfig] = None,\n        tool_call_id: Optional[str] = None,\n        **kwargs: Any,\n    ) -> Any:\n        \"\"\"Run the tool asynchronously.\n    \n        Args:\n            tool_input: The input to the tool.\n            verbose: Whether to log the tool's progress. Defaults to None.\n            start_color: The color to use when starting the tool. Defaults to 'green'.\n            color: The color to use when ending the tool. Defaults to 'green'.\n            callbacks: Callbacks to be called during tool execution. Defaults to None.\n            tags: Optional list of tags associated with the tool. Defaults to None.\n            metadata: Optional metadata associated with the tool. Defaults to None.\n            run_name: The name of the run. Defaults to None.\n            run_id: The id of the run. Defaults to None.\n            config: The configuration for the tool. Defaults to None.\n            tool_call_id: The id of the tool call. Defaults to None.\n            kwargs: Additional arguments to pass to the tool\n    \n        Returns:\n            The output of the tool.\n    \n        Raises:\n            ToolException: If an error occurs during tool execution.\n        \"\"\"\n        callback_manager = AsyncCallbackManager.configure(\n            callbacks,\n            self.callbacks,\n            self.verbose or bool(verbose),\n            tags,\n            self.tags,\n            metadata,\n            self.metadata,\n        )\n        run_manager = await callback_manager.on_tool_start(\n            {\"name\": self.name, \"description\": self.description},\n            tool_input if isinstance(tool_input, str) else str(tool_input),\n            color=start_color,\n            name=run_name,\n            run_id=run_id,\n            # Inputs by definition should always be dicts.\n            # For now, it's unclear whether this assumption is ever violated,\n            # but if it is we will send a `None` value to the callback instead\n            # TODO: will need to address issue via a patch.\n            inputs=tool_input if isinstance(tool_input, dict) else None,\n            **kwargs,\n        )\n        content = None\n        artifact = None\n        error_to_raise: Optional[Union[Exception, KeyboardInterrupt]] = None\n        try:\n            tool_args, tool_kwargs = self._to_args_and_kwargs(tool_input)\n            child_config = patch_config(config, callbacks=run_manager.get_child())\n            context = copy_context()\n            context.run(_set_config_context, child_config)\n            func_to_check = (\n                self._run if self.__class__._arun is BaseTool._arun else self._arun\n            )\n            if signature(func_to_check).parameters.get(\"run_manager\"):\n                tool_kwargs[\"run_manager\"] = run_manager\n            if config_param := _get_runnable_config_param(func_to_check):\n                tool_kwargs[config_param] = config\n    \n>           coro = context.run(self._arun, *tool_args, **tool_kwargs)\nE           TypeError: NFTRankingExecutor._arun() missing 1 required positional argument: 'limit'\n\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tools.py:716: TypeError","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[{"name":"event_loop_policy","time":{"start":1730429119033,"stop":1730429119033,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"market_analysis_agent","time":{"start":1730429119033,"stop":1730429125512,"duration":6479},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"event_loop","time":{"start":1730429125513,"stop":1730429125513,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"testStage":{"status":"broken","statusMessage":"TypeError: NFTRankingExecutor._arun() missing 1 required positional argument: 'limit'","statusTrace":"market_analysis_agent = AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n  agent_scratchpad: Runnab...(name='DuckDuckGoSearchExecutor'), FundingRateExecutor(), PriceExecutor(), CoinMarketExecutor(), NFTRankingExecutor()])\n\n    @pytest.mark.asyncio\n    async def test_query_nft_ranking(market_analysis_agent):\n        events = market_analysis_agent.astream_events(\n            {\"messages\": [HumanMessage(content=\"What are the top 5 NFT collections?\", name=\"human\")]}, version=\"v1\"\n        )\n    \n        tool_end_count = 0\n>       async for event in events:\n\nagent_trajectory/market_analysis.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/runnables/base.py:1246: in astream_events\n    async for event in event_stream:\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/event_stream.py:778: in _astream_events_implementation_v1\n    async for log in _astream_log_implementation(  # type: ignore[misc]\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:670: in _astream_log_implementation\n    await task\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:624: in consume_astream\n    async for chunk in runnable.astream(input, config, **kwargs):\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1595: in astream\n    async for step in iterator:\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent_iterator.py:246: in __aiter__\n    async for chunk in self.agent_executor._aiter_next_step(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1360: in _aiter_next_step\n    result = await asyncio.gather(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain/agents/agent.py:1393: in _aperform_agent_action\n    observation = await tool.arun(\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tools.py:747: in arun\n    raise error_to_raise\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = NFTRankingExecutor(), tool_input = {}, verbose = True\nstart_color = 'green', color = 'yellow'\ncallbacks = <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7fbea7c7dc90>\ntags = None, metadata = None, run_name = None, run_id = None, config = None\ntool_call_id = None, kwargs = {}\ncallback_manager = <langchain_core.callbacks.manager.AsyncCallbackManager object at 0x7fbea6b07690>\n\n    async def arun(\n        self,\n        tool_input: Union[str, Dict],\n        verbose: Optional[bool] = None,\n        start_color: Optional[str] = \"green\",\n        color: Optional[str] = \"green\",\n        callbacks: Callbacks = None,\n        *,\n        tags: Optional[List[str]] = None,\n        metadata: Optional[Dict[str, Any]] = None,\n        run_name: Optional[str] = None,\n        run_id: Optional[uuid.UUID] = None,\n        config: Optional[RunnableConfig] = None,\n        tool_call_id: Optional[str] = None,\n        **kwargs: Any,\n    ) -> Any:\n        \"\"\"Run the tool asynchronously.\n    \n        Args:\n            tool_input: The input to the tool.\n            verbose: Whether to log the tool's progress. Defaults to None.\n            start_color: The color to use when starting the tool. Defaults to 'green'.\n            color: The color to use when ending the tool. Defaults to 'green'.\n            callbacks: Callbacks to be called during tool execution. Defaults to None.\n            tags: Optional list of tags associated with the tool. Defaults to None.\n            metadata: Optional metadata associated with the tool. Defaults to None.\n            run_name: The name of the run. Defaults to None.\n            run_id: The id of the run. Defaults to None.\n            config: The configuration for the tool. Defaults to None.\n            tool_call_id: The id of the tool call. Defaults to None.\n            kwargs: Additional arguments to pass to the tool\n    \n        Returns:\n            The output of the tool.\n    \n        Raises:\n            ToolException: If an error occurs during tool execution.\n        \"\"\"\n        callback_manager = AsyncCallbackManager.configure(\n            callbacks,\n            self.callbacks,\n            self.verbose or bool(verbose),\n            tags,\n            self.tags,\n            metadata,\n            self.metadata,\n        )\n        run_manager = await callback_manager.on_tool_start(\n            {\"name\": self.name, \"description\": self.description},\n            tool_input if isinstance(tool_input, str) else str(tool_input),\n            color=start_color,\n            name=run_name,\n            run_id=run_id,\n            # Inputs by definition should always be dicts.\n            # For now, it's unclear whether this assumption is ever violated,\n            # but if it is we will send a `None` value to the callback instead\n            # TODO: will need to address issue via a patch.\n            inputs=tool_input if isinstance(tool_input, dict) else None,\n            **kwargs,\n        )\n        content = None\n        artifact = None\n        error_to_raise: Optional[Union[Exception, KeyboardInterrupt]] = None\n        try:\n            tool_args, tool_kwargs = self._to_args_and_kwargs(tool_input)\n            child_config = patch_config(config, callbacks=run_manager.get_child())\n            context = copy_context()\n            context.run(_set_config_context, child_config)\n            func_to_check = (\n                self._run if self.__class__._arun is BaseTool._arun else self._arun\n            )\n            if signature(func_to_check).parameters.get(\"run_manager\"):\n                tool_kwargs[\"run_manager\"] = run_manager\n            if config_param := _get_runnable_config_param(func_to_check):\n                tool_kwargs[config_param] = config\n    \n>           coro = context.run(self._arun, *tool_args, **tool_kwargs)\nE           TypeError: NFTRankingExecutor._arun() missing 1 required positional argument: 'limit'\n\n/opt/hostedtoolcache/Python/3.11.5/x64/lib/python3.11/site-packages/langchain_core/tools.py:716: TypeError","steps":[],"attachments":[{"uid":"3b1ca0e7d0f76c0d","name":"stdout","source":"3b1ca0e7d0f76c0d.txt","type":"text/plain","size":109},{"uid":"18b1790c927ca872","name":"stderr","source":"18b1790c927ca872.txt","type":"text/plain","size":125}],"parameters":[],"shouldDisplayMessage":true,"stepsCount":0,"attachmentsCount":2,"hasContent":true,"attachmentStep":false},"afterStages":[{"name":"event_loop::3","time":{"start":1730429138103,"stop":1730429138103,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"event_loop::_close_event_loop","time":{"start":1730429138103,"stop":1730429138103,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"event_loop::_restore_policy","time":{"start":1730429138103,"stop":1730429138103,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false},{"name":"event_loop::_provide_clean_event_loop","time":{"start":1730429138103,"stop":1730429138103,"duration":0},"status":"passed","steps":[],"attachments":[],"parameters":[],"shouldDisplayMessage":false,"stepsCount":0,"attachmentsCount":0,"hasContent":false,"attachmentStep":false}],"labels":[{"name":"tag","value":"asyncio"},{"name":"parentSuite","value":"tests.agent_trajectory"},{"name":"suite","value":"market_analysis"},{"name":"host","value":"fv-az1152-915"},{"name":"thread","value":"6046-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"tests.agent_trajectory.market_analysis"},{"name":"resultFormat","value":"allure2"}],"parameters":[{"name":"__pytest_repeat_step_number","value":"2"}],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Test defects","matchedStatuses":[],"flaky":false}],"tags":["asyncio"]},"source":"6dc17a8b353cd1df.json","parameterValues":["2"]}